{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8beb036f",
      "metadata": {
        "id": "8beb036f"
      },
      "source": [
        "# CS 5588 — Week 2 Hands-On: Applied RAG for Product & Venture Development (Two-Step)\n",
        "**Initiation (20 min, Jan 27)** → **Completion (60 min, Jan 29)**\n",
        "\n",
        "**Submission:** Survey + GitHub  \n",
        "**Due:** **Jan 29 (Thu), end of class**\n",
        "\n",
        "## New Requirement (Important)\n",
        "For **full credit (2% individual)** you must:\n",
        "1) Use **your own project-aligned dataset** (not only benchmark)  \n",
        "2) Add **your own explanations** for key steps\n",
        "\n",
        "### ✅ “Cell Description” rule (same style as CS 5542)\n",
        "After each **IMPORTANT** code cell, add a short Markdown **Cell Description** (2–5 sentences):\n",
        "- What the cell does\n",
        "- Why it matters for a **product-grade** RAG system\n",
        "- Any design choices (chunk size, α, reranker, etc.)\n",
        "\n",
        "> Treat these descriptions as **mini system documentation** (engineering + product thinking).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0e43e2d",
      "metadata": {
        "id": "d0e43e2d"
      },
      "source": [
        "## Project Dataset Guide (Required for Full Credit)\n",
        "\n",
        "### Minimum requirements\n",
        "- **5–25 documents** (start small; scale later)\n",
        "- Prefer **plain text** documents (`.txt`)\n",
        "- Put files in a folder named: `project_data/`\n",
        "\n",
        "### Recommended dataset types (choose one)\n",
        "- Policies / guidelines / compliance docs\n",
        "- Technical docs / manuals / SOPs\n",
        "- Customer support FAQs / tickets (de-identified)\n",
        "- Research notes / literature summaries\n",
        "- Domain corpus (healthcare, cybersecurity, business, etc.)\n",
        "\n",
        "> Benchmarks are optional, but **cannot** earn full credit by themselves.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7f68d33",
      "metadata": {
        "id": "e7f68d33"
      },
      "source": [
        "## 0) One-Click Setup + Import Check  ✅ **IMPORTANT: Add Cell Description after running**\n",
        "If you are in **Google Colab**, run the install cell below, then **Runtime → Restart session** if imports fail.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ddaa1c18",
      "metadata": {
        "id": "ddaa1c18",
        "outputId": "2860434b-1f53-441f-f988-87615130f1f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m818.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "google-adk 1.21.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.1 which is incompatible.\n",
            "google-adk 1.21.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mPython: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "Platform: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "✅ If imports fail later: Runtime → Restart session and run again.\n"
          ]
        }
      ],
      "source": [
        "# CS 5588 Lab 2 — One-click dependency install (Colab)\n",
        "!pip -q install -U sentence-transformers chromadb faiss-cpu scikit-learn rank-bm25 transformers accelerate\n",
        "\n",
        "import sys, platform\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"Platform:\", platform.platform())\n",
        "print(\"✅ If imports fail later: Runtime → Restart session and run again.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab532915",
      "metadata": {
        "id": "ab532915"
      },
      "source": [
        "### ✍️ Cell Description (Student)\n",
        "Write 2–5 sentences explaining what the setup cell does and why restarting the runtime sometimes matters after pip installs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell sets up and installs  everything needed to run the RAG system by installing all required libraries in one step. Doing this upfront avoids version conflicts and makes the notebook easy for others to run without extra setup. Printing the Python and platform info helps quickly spot environment-related issues if something breaks. The restart note is a practical safeguard for Colab quirks so the workflow stays smooth."
      ],
      "metadata": {
        "id": "qGjJHVFZxLhw"
      },
      "id": "qGjJHVFZxLhw"
    },
    {
      "cell_type": "markdown",
      "id": "49154e13",
      "metadata": {
        "id": "49154e13"
      },
      "source": [
        "# STEP 1 — INITIATION (Jan 27, 20 minutes)\n",
        "**Goal:** Define the **product**, **users**, **dataset reality**, and **trust risks**.\n",
        "\n",
        "> This is a **product milestone**, not a coding demo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58216603",
      "metadata": {
        "id": "58216603"
      },
      "source": [
        "## 1A) Product Framing (Required)  ✅ **IMPORTANT: Add Cell Description after running**\n",
        "Fill in the template below like a founder/product lead.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "214ee1ba",
      "metadata": {
        "id": "214ee1ba",
        "outputId": "4a062798-2d27-4b2a-bc05-1cc83cc655c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'product_name': 'AI-Powered Weather & Climate Intelligence System for Personalized Decision Support',\n",
              " 'target_users': 'General users, travelers, researchers, and analysts who need actionable weather insights for travel, daily activities, or climate research.',\n",
              " 'core_problem': 'Existing apps mainly focus on forecasts and alertsbut lack contextual interpretation, personalization and explainable insights',\n",
              " 'why_rag_not_chatbot': 'RAG enables the system to retrieve real-time weather data, historical climate records and severe weather alerts that are accurate and graunded. A standard bot is relies on pre-trained knowledge and could hallucinate or provide outdated weather information.',\n",
              " 'failure_harms_who_and_how': 'Incorrect forecasts, misinterpreted AI advice, or missed severe weather alerts could mislead users, causing travel disruptions, safety risks, or property damage. Poor explainability could also reduce trust in the system.'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "product = {\n",
        "  \"product_name\": \"AI-Powered Weather & Climate Intelligence System for Personalized Decision Support\",\n",
        "  \"target_users\": \"General users, travelers, researchers, and analysts who need actionable weather insights for travel, daily activities, or climate research.\",\n",
        "  \"core_problem\": \"Existing apps mainly focus on forecasts and alertsbut lack contextual interpretation, personalization and explainable insights\",\n",
        "  \"why_rag_not_chatbot\": \"RAG enables the system to retrieve real-time weather data, historical climate records and severe weather alerts that are accurate and graunded. A standard bot is relies on pre-trained knowledge and could hallucinate or provide outdated weather information.\",\n",
        "  \"failure_harms_who_and_how\": \"Incorrect forecasts, misinterpreted AI advice, or missed severe weather alerts could mislead users, causing travel disruptions, safety risks, or property damage. Poor explainability could also reduce trust in the system.\",\n",
        "}\n",
        "product\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "490a084a",
      "metadata": {
        "id": "490a084a"
      },
      "source": [
        "### ✍️ Cell Description (Student)\n",
        "Explain your product in 3–5 sentences: who the user is, what pain point exists today, and why grounded RAG helps.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This AI-powered weather system helps users—travelers, students, or anyone planning daily activities—get clear and useful weather information. Most apps only show forecasts and alerts, leaving users to figure out what it means. Our system combines real-time weather, historical trends, and severe weather alerts to give personalized, easy-to-understand guidance. Using RAG, the AI bases its answers on real data, so users get accurate and trustworthy recommendations. This helps people plan trips, daily activities, and stay safe during extreme weather."
      ],
      "metadata": {
        "id": "-nO4oJnAoHgA"
      },
      "id": "-nO4oJnAoHgA"
    },
    {
      "cell_type": "markdown",
      "id": "179e8e12",
      "metadata": {
        "id": "179e8e12"
      },
      "source": [
        "## 1B) Dataset Reality Plan (Required)  ✅ **IMPORTANT: Add Cell Description after running**\n",
        "Describe where your data comes from **in the real world**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "282cb6f9",
      "metadata": {
        "id": "282cb6f9",
        "outputId": "ae411273-291c-4396-8b78-68f5251f5ccb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data_owner': 'Public agencies and APIs (NOAA, NASA, city open data portals, OpenWeather API)',\n",
              " 'data_sensitivity': 'Public, no confidential data involved',\n",
              " 'document_types': 'Real-time weather readings, historical climate data, severe weather alerts, geospatial data',\n",
              " 'expected_scale_in_production': 'Millions of data points daily from multiple cities; historical datasets spanning years for trend analysis',\n",
              " 'data_reality_check_paragraph': 'The system gets real-time weather data from APIs like OpenWeather and city open data portals, while historical climate data comes from NOAA and NASA. The data comes in different formats—like JSON, CSV, or NetCDF—so it needs to be cleaned and standardized before use. Real-time APIs can have rate limits or occasional downtime, and historical datasets may have missing or inconsistent records. By handling these challenges carefully, the system can provide accurate forecasts, trend analysis, and personalized weather insights to users.”'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "dataset_plan = {\n",
        "  \"data_owner\": \"Public agencies and APIs (NOAA, NASA, city open data portals, OpenWeather API)\",              # company / agency / public / internal team\n",
        "  \"data_sensitivity\": \"Public, no confidential data involved\",        # public / internal / regulated / confidential\n",
        "  \"document_types\": \"Real-time weather readings, historical climate data, severe weather alerts, geospatial data\",          # policies, manuals, reports, research, etc.\n",
        "  \"expected_scale_in_production\": \"Millions of data points daily from multiple cities; historical datasets spanning years for trend analysis\",  # e.g., 200 docs, 10k docs, etc.\n",
        "  \"data_reality_check_paragraph\": \"The system gets real-time weather data from APIs like OpenWeather and city open data portals, while historical climate data comes from NOAA and NASA. The data comes in different formats—like JSON, CSV, or NetCDF—so it needs to be cleaned and standardized before use. Real-time APIs can have rate limits or occasional downtime, and historical datasets may have missing or inconsistent records. By handling these challenges carefully, the system can provide accurate forecasts, trend analysis, and personalized weather insights to users.”\",\n",
        "}\n",
        "dataset_plan\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e2da001",
      "metadata": {
        "id": "3e2da001"
      },
      "source": [
        "### ✍️ Cell Description (Student)\n",
        "Write 2–5 sentences describing where this data would come from in a real deployment and any privacy/regulatory constraints.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a real deployment, our system would collect real-time weather from services like OpenWeather and city open data portals, while historical climate records come from NOAA and NASA. The data comes in different formats and sometimes has missing or inconsistent entries, so we clean and standardize it before use. All the sources are public, so privacy isn’t an issue, but we still need to handle large volumes carefully to make sure users always get accurate and reliable weather insights."
      ],
      "metadata": {
        "id": "eoH1rEX_pW7z"
      },
      "id": "eoH1rEX_pW7z"
    },
    {
      "cell_type": "markdown",
      "id": "2df3ac72",
      "metadata": {
        "id": "2df3ac72"
      },
      "source": [
        "## 1C) User Stories + Mini Rubric (Required)  ✅ **IMPORTANT: Add Cell Description after running**\n",
        "Define **3 user stories** (U1 normal, U2 high-stakes, U3 ambiguous/failure) + rubric for evidence and correctness.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0a72b8eb",
      "metadata": {
        "id": "0a72b8eb",
        "outputId": "4e8d7a40-ecc3-4ff7-f5b4-1e710f271c55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'U1_normal': {'user_story': 'As a general user, I want to check the current weather and hourly forecast for my city so that I can plan my day effectively.',\n",
              "  'acceptable_evidence': ['The dashboard shows real-time weather and hourly forecasts for the selected city.',\n",
              "   'User can see temperature, precipitation, wind, and humidity for their location.'],\n",
              "  'correct_answer_must_include': ['Real-time weather data is displayed accurately',\n",
              "   'Forecast information is easily readable and understandable']},\n",
              " 'U2_high_stakes': {'user_story': 'As a traveler, I want to receive alerts for severe weather events so that I can I can avoid dangerous conditions and plan my trips safely..',\n",
              "  'acceptable_evidence': ['System sends notifications or shows alerts for floods, storms, snow, or hurricanes.',\n",
              "   'User can view details of the alert and recommended precautions.'],\n",
              "  'correct_answer_must_include': ['Severe weather alerts are timely and accurate',\n",
              "   'AI provides actionable advice based on the alerts']},\n",
              " 'U3_ambiguous_failure': {'user_story': 'As a researcher, I want to compare current weather with historical trends so that I can understand anomalies or patterns over time',\n",
              "  'acceptable_evidence': ['Dashboard visualizes historical climate trends alongside current data.',\n",
              "   'User can analyze deviations from typical patterns for their city or region.'],\n",
              "  'correct_answer_must_include': ['Historical climate data is correctly integrated and visualized',\n",
              "   'Anomalies or patterns are highlighted clearly']}}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "user_stories = {\n",
        "  \"U1_normal\": {\n",
        "    \"user_story\": \"As a general user, I want to The dashboard shows real-time weather and hourly forecasts for the selected city.check the current weather and hourly forecast for my city so that I can plan my day effectively.\",\n",
        "    \"acceptable_evidence\": [\"The dashboard shows real-time weather and hourly forecasts for the selected city.\",\n",
        "        \"User can see temperature, precipitation, wind, and humidity for their location.\"],\n",
        "    \"correct_answer_must_include\": [\"Real-time weather data is displayed accurately\", \"Forecast information is easily readable and understandable\"],\n",
        "  },\n",
        "  \"U2_high_stakes\": {\n",
        "    \"user_story\": \"As a traveler, I want to receive alerts for severe weather events so that I can I can avoid dangerous conditions and plan my trips safely..\",\n",
        "    \"acceptable_evidence\":[ \"System sends notifications or shows alerts for floods, storms, snow, or hurricanes.\",\n",
        "        \"User can view details of the alert and recommended precautions.\"\n",
        "    ],\n",
        "    \"correct_answer_must_include\": [\"Severe weather alerts are timely and accurate\",\n",
        "        \"AI provides actionable advice based on the alerts\"],\n",
        "  },\n",
        "  \"U3_ambiguous_failure\": {\n",
        "    \"user_story\": \"As a researcher, I want to compare current weather with historical trends so that I can understand anomalies or patterns over time\",\n",
        "    \"acceptable_evidence\": [\"Dashboard visualizes historical climate trends alongside current data.\",\n",
        "        \"User can analyze deviations from typical patterns for their city or region.\"],\n",
        "    \"correct_answer_must_include\": [\"Historical climate data is correctly integrated and visualized\",\n",
        "        \"Anomalies or patterns are highlighted clearly\"],\n",
        "  },\n",
        "}\n",
        "user_stories\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d5189f5",
      "metadata": {
        "id": "8d5189f5"
      },
      "source": [
        "### ✍️ Cell Description (Student)\n",
        "Explain why U2 is “high-stakes” and what the system must do to avoid harm (abstain, cite evidence, etc.).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "U2 is considered “high-stakes” because it affects users safety—if the system misses a severe weather alert, users could be caught in dangerous situations like floods, storms, or snowstorms. To prevent harm, the system must use trusted sources like NOAA, NASA, and city open data portals, show clearly where the information comes from, and explain the alert in simple terms. If the data is uncertain or missing, the system should warn users and avoid giving misleading advice, so they can make safe, informed decisions.\n"
      ],
      "metadata": {
        "id": "QrV7HyFMrptG"
      },
      "id": "QrV7HyFMrptG"
    },
    {
      "cell_type": "markdown",
      "id": "3b9c075c",
      "metadata": {
        "id": "3b9c075c"
      },
      "source": [
        "## 1D) Trust & Risk Table (Required)\n",
        "Fill at least **3 rows**. These risks should match your product and user stories.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "972f5b88",
      "metadata": {
        "id": "972f5b88",
        "outputId": "bd029b6c-3c7e-404f-ffbe-c26b6e6b602d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'risk': 'Hallucination',\n",
              "  'example_failure': 'The AI says there will be a snowstorm in New York tomorrow, but no such storm is predicted in any data source.',\n",
              "  'real_world_consequence': 'Users might cancel plans unnecessarily or panic, reducing trust in the system.',\n",
              "  'safeguard_idea': 'Force citations from trusted sources (NOAA, NASA, city portals) and abstain if data is insufficient.'},\n",
              " {'risk': 'Omission',\n",
              "  'example_failure': 'The system fails to alert users about an approaching hurricane because the data wasn’t retrieved properly.',\n",
              "  'real_world_consequence': 'Users could be caught in dangerous conditions, risking life, health, and property.',\n",
              "  'safeguard_idea': 'Use recall tuning and hybrid retrieval from multiple sources to ensure alerts are not missed.'},\n",
              " {'risk': 'Bias/Misleading',\n",
              "  'example_failure': 'The AI highlights favorable weather for one city while underestimating nearby regions at risk of severe weather.',\n",
              "  'real_world_consequence': 'Users may make unsafe travel or activity decisions, lowering trust and increasing exposure to hazards.',\n",
              "  'safeguard_idea': 'Apply reranking rules, incorporate human review for critical alerts, and clearly communicate uncertainty.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "risk_table = [\n",
        "  {\n",
        "    \"risk\": \"Hallucination\",\n",
        "    \"example_failure\": \"The AI says there will be a snowstorm in New York tomorrow, but no such storm is predicted in any data source.\",\n",
        "    \"real_world_consequence\": \"Users might cancel plans unnecessarily or panic, reducing trust in the system.\",\n",
        "    \"safeguard_idea\": \"Force citations from trusted sources (NOAA, NASA, city portals) and abstain if data is insufficient.\"\n",
        "  },\n",
        "  {\n",
        "    \"risk\": \"Omission\",\n",
        "    \"example_failure\": \"The system fails to alert users about an approaching hurricane because the data wasn’t retrieved properly.\",\n",
        "    \"real_world_consequence\": \"Users could be caught in dangerous conditions, risking life, health, and property.\",\n",
        "    \"safeguard_idea\": \"Use recall tuning and hybrid retrieval from multiple sources to ensure alerts are not missed.\"\n",
        "  },\n",
        "  {\n",
        "    \"risk\": \"Bias/Misleading\",\n",
        "    \"example_failure\": \"The AI highlights favorable weather for one city while underestimating nearby regions at risk of severe weather.\",\n",
        "    \"real_world_consequence\": \"Users may make unsafe travel or activity decisions, lowering trust and increasing exposure to hazards.\",\n",
        "    \"safeguard_idea\": \"Apply reranking rules, incorporate human review for critical alerts, and clearly communicate uncertainty.\"\n",
        "  },\n",
        "]\n",
        "\n",
        "risk_table\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33fe422b",
      "metadata": {
        "id": "33fe422b"
      },
      "source": [
        "✅ **Step 1 Checkpoint (End of Jan 27)**\n",
        "Commit (or submit) your filled templates:\n",
        "- `product`, `dataset_plan`, `user_stories`, `risk_table`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9645a53",
      "metadata": {
        "id": "b9645a53"
      },
      "source": [
        "# STEP 2 — COMPLETION (Jan 29, 60 minutes)\n",
        "**Goal:** Build a working **product-grade** RAG pipeline:\n",
        "Chunking → Keyword + Vector Retrieval → Hybrid α → Governance Rerank → Grounded Answer → Evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "849ea98a",
      "metadata": {
        "id": "849ea98a"
      },
      "source": [
        "## 2A) Project Dataset Setup (Required for Full Credit)  ✅ **IMPORTANT: Add Cell Description after running**\n",
        "\n",
        "### Colab Upload Tips\n",
        "- Left sidebar → **Files** → Upload `.txt`\n",
        "- Place them into `project_data/`\n",
        "\n",
        "This cell creates the folder and shows how many files were found.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "90a38f48",
      "metadata": {
        "id": "90a38f48",
        "outputId": "5275ae2a-bde8-4a83-9043-cee7b83e1468",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ project_data/ ready | moved: 1 | files: 10\n",
            "Example files: ['project_data/Station_10_weather.txt', 'project_data/Station_1_weather.txt', 'project_data/Station_2_weather.txt', 'project_data/Station_3_weather.txt', 'project_data/Station_4_weather.txt']\n"
          ]
        }
      ],
      "source": [
        "import os, glob, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_FOLDER = \"project_data\"\n",
        "os.makedirs(PROJECT_FOLDER, exist_ok=True)\n",
        "\n",
        "# (Optional helper) Move any .txt in current directory into project_data/\n",
        "moved = 0\n",
        "for fp in glob.glob(\"*.txt\"):\n",
        "    shutil.move(fp, os.path.join(PROJECT_FOLDER, os.path.basename(fp)))\n",
        "    moved += 1\n",
        "\n",
        "files = sorted(glob.glob(os.path.join(PROJECT_FOLDER, \"*.txt\")))\n",
        "print(\"✅ project_data/ ready | moved:\", moved, \"| files:\", len(files))\n",
        "print(\"Example files:\", files[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ka_9jb-AJ2ky",
        "outputId": "7c01e8c2-e94d-48d9-e2f0-843b4d18a2d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ka_9jb-AJ2ky",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec380ad4",
      "metadata": {
        "id": "ec380ad4"
      },
      "source": [
        "### ✍️ Cell Description (Student)\n",
        "List what dataset you used, how many docs, and why they reflect your product scenario (not just a toy example).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Files used: ghcnd-stations.txt and weather.txt\n",
        "\n",
        "Number of documents: 2 text files (CSV/structured text format)\n",
        "\n",
        "Reason for use: These datasets reflect real-world weather data—station metadata and historical weather records—which aligns with a product scenario like climate analysis, forecasting, or environmental monitoring. They are more than toy examples because they contain structured information that can be programmatically queried, filtered, and analyzed to support meaningful insights or applications"
      ],
      "metadata": {
        "id": "_I7crDMXK30Q"
      },
      "id": "_I7crDMXK30Q"
    },
    {
      "cell_type": "markdown",
      "id": "a487a1c7",
      "metadata": {
        "id": "a487a1c7"
      },
      "source": [
        "## 2B) Load Documents + Build Chunks  ✅ **IMPORTANT: Add Cell Description after running**\n",
        "This milestone cell loads `.txt` documents and produces chunks using either **fixed** or **semantic** chunking.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "13a081d6",
      "metadata": {
        "id": "13a081d6",
        "outputId": "26c739f7-4bbb-4902-88e9-64c5356d788b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded docs: 10\n",
            "Chunking: semantic | total chunks: 20\n",
            "Sample chunk id: Station_10_weather.txt::c0\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def load_project_docs(folder=\"project_data\", max_docs=25):\n",
        "    paths = sorted(Path(folder).glob(\"*.txt\"))[:max_docs]\n",
        "    docs = []\n",
        "    for p in paths:\n",
        "        txt = p.read_text(encoding=\"utf-8\", errors=\"ignore\").strip()\n",
        "        if txt:\n",
        "            docs.append({\"doc_id\": p.name, \"text\": txt})\n",
        "    return docs\n",
        "\n",
        "def fixed_chunk(text, chunk_size=900, overlap=150):\n",
        "    # Character-based chunking for speed + simplicity\n",
        "    chunks, i = [], 0\n",
        "    while i < len(text):\n",
        "        chunks.append(text[i:i+chunk_size])\n",
        "        i += (chunk_size - overlap)\n",
        "    return [c.strip() for c in chunks if c.strip()]\n",
        "\n",
        "def semantic_chunk(text, max_chars=1000):\n",
        "    # Paragraph-based packing\n",
        "    paras = [p.strip() for p in re.split(r\"\\n\\s*\\n\", text) if p.strip()]\n",
        "    chunks, cur = [], \"\"\n",
        "    for p in paras:\n",
        "        if len(cur) + len(p) + 2 <= max_chars:\n",
        "            cur = (cur + \"\\n\\n\" + p).strip()\n",
        "        else:\n",
        "            if cur: chunks.append(cur)\n",
        "            cur = p\n",
        "    if cur: chunks.append(cur)\n",
        "    return chunks\n",
        "\n",
        "# ---- Choose chunking policy ----\n",
        "CHUNKING = \"semantic\"   # \"fixed\" or \"semantic\"\n",
        "FIXED_SIZE = 900\n",
        "FIXED_OVERLAP = 150\n",
        "SEM_MAX = 1000\n",
        "\n",
        "docs = load_project_docs(PROJECT_FOLDER, max_docs=25)\n",
        "print(\"Loaded docs:\", len(docs))\n",
        "\n",
        "all_chunks = []\n",
        "for d in docs:\n",
        "    chunks = fixed_chunk(d[\"text\"], FIXED_SIZE, FIXED_OVERLAP) if CHUNKING == \"fixed\" else semantic_chunk(d[\"text\"], SEM_MAX)\n",
        "    for j, c in enumerate(chunks):\n",
        "        all_chunks.append({\"chunk_id\": f'{d[\"doc_id\"]}::c{j}', \"doc_id\": d[\"doc_id\"], \"text\": c})\n",
        "\n",
        "print(\"Chunking:\", CHUNKING, \"| total chunks:\", len(all_chunks))\n",
        "print(\"Sample chunk id:\", all_chunks[0][\"chunk_id\"] if all_chunks else \"NO CHUNKS (upload .txt files first)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "204e5e83",
      "metadata": {
        "id": "204e5e83"
      },
      "source": [
        "### ✍️ Cell Description (Student)\n",
        "Explain why you chose fixed vs semantic chunking for your product, and how chunking affects precision/recall and trust.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell loads all .txt files from the project_data/ folder (up to 25 files) and prepares them for analysis by splitting each document into smaller, manageable pieces called chunks. Each document is stored with a doc_id and its text content, while each chunk keeps track of which document it came from and is assigned a unique chunk_id. The cell supports two chunking strategies: fixed chunking, which breaks text into equal-sized character blocks with some overlap to preserve context, and semantic chunking, which groups paragraphs together up to a maximum length to retain logical meaning. This process ensures that even long documents can be efficiently processed, searched, or embedded for AI-driven tasks, while maintaining context and structure. After running this cell, the documents are fully loaded and converted into chunks, ready for downstream analysis or retrieval."
      ],
      "metadata": {
        "id": "HZYHtsbzLJrF"
      },
      "id": "HZYHtsbzLJrF"
    },
    {
      "cell_type": "markdown",
      "id": "9bec9a30",
      "metadata": {
        "id": "9bec9a30"
      },
      "source": [
        "## 2C) Build Retrieval Engines (BM25 + Vector Index)  ✅ **IMPORTANT: Add Cell Description after running**\n",
        "This cell builds:\n",
        "- **Keyword retrieval** (BM25) for exact matches / compliance\n",
        "- **Vector retrieval** (embeddings + FAISS) for semantic matches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "d0484f1a",
      "metadata": {
        "id": "d0484f1a",
        "outputId": "eaa8c02b-156f-491b-c246-de75637a68fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "bc638f11db8741ceb46a93e4571d734f",
            "898ce98f012f4395bcbf2f7f4a4c868d",
            "887f14dd3cc3425eb97845ee6571cee8",
            "e72448fc00e14d0d8a036660fe69609e",
            "475a3f79820640119bdd4d39f79b6698",
            "59f2f3b1becd4a9cba246a20cfe794e7",
            "e7fa541387314e20be73d682c8d77188",
            "5061c75a45814275a2cb734df8b11fbc",
            "905c2e265628494695d2fcaa119e6a69",
            "ea848ac9d9404f5d9c8566ad0a18b1aa",
            "419d789129184beaad93b0a6e18cc26e",
            "20fa2689c85d4da885971c8602c06cd7",
            "28b7378d38d84f30a5c0ead9498a8f27",
            "fdab3a67059f40098874d48820bb8eab",
            "f005b5767f5a4be1b8c525792760949c",
            "02a67ee9f5124960bb48df85781121df",
            "55e59af09e8f46d789387ca17f1e50c9",
            "710e19a928ad44c687936eb3582415d8",
            "fd83efdf007b4c158fe227ec89ad1f85",
            "9ffaec9dfd6f4f2cb704cd8b976cac8d",
            "d960103f18444ffca04fce888870ba14",
            "77024a81b7e845bca51351a790d61a87"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc638f11db8741ceb46a93e4571d734f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20fa2689c85d4da885971c8602c06cd7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Vector index built | chunks: 20 | dim: 384\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from rank_bm25 import BM25Okapi\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "\n",
        "# ----- Keyword (BM25) -----\n",
        "tokenized = [c[\"text\"].lower().split() for c in all_chunks]\n",
        "bm25 = BM25Okapi(tokenized) if len(tokenized) else None\n",
        "\n",
        "def keyword_search(query, k=10):\n",
        "    if bm25 is None:\n",
        "        return []\n",
        "    scores = bm25.get_scores(query.lower().split())\n",
        "    idx = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:k]\n",
        "    return [(all_chunks[i], float(scores[i])) for i in idx]\n",
        "\n",
        "# ----- Vector (Embeddings + FAISS) -----\n",
        "EMB_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "embedder = SentenceTransformer(EMB_MODEL_NAME)\n",
        "\n",
        "chunk_texts = [c[\"text\"] for c in all_chunks]\n",
        "if len(chunk_texts) > 0:\n",
        "    emb = embedder.encode(chunk_texts, show_progress_bar=True, normalize_embeddings=True)\n",
        "    emb = np.asarray(emb, dtype=\"float32\")\n",
        "\n",
        "    index = faiss.IndexFlatIP(emb.shape[1])\n",
        "    index.add(emb)\n",
        "\n",
        "    def vector_search(query, k=10):\n",
        "        q = embedder.encode([query], normalize_embeddings=True).astype(\"float32\")\n",
        "        scores, idx = index.search(q, k)\n",
        "        out = [(all_chunks[int(i)], float(s)) for s, i in zip(scores[0], idx[0])]\n",
        "        return out\n",
        "    print(\"✅ Vector index built | chunks:\", len(all_chunks), \"| dim:\", emb.shape[1])\n",
        "else:\n",
        "    index = None\n",
        "    def vector_search(query, k=10): return []\n",
        "    print(\"⚠️ No chunks found. Upload .txt files to project_data/ and rerun.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7cb1a14",
      "metadata": {
        "id": "c7cb1a14"
      },
      "source": [
        "### ✍️ Cell Description (Student)\n",
        "Explain why your product needs both keyword and vector retrieval (what each catches that the other misses).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell builds two types of search engines for our weather AI system. Keyword search (BM25) helps find exact terms, like a specific station name, date, or weather metric, which is important for precise queries or compliance checks. Vector search (embeddings + FAISS) understands the meaning behind the text, so it can retrieve relevant information even when the wording differs—for example, finding “rainfall trends” even if the text says “precipitation patterns.” Combining both ensures users can quickly get accurate weather data or insights, whether they know the exact terms or are exploring broader patterns."
      ],
      "metadata": {
        "id": "J9B_n3hELyWh"
      },
      "id": "J9B_n3hELyWh"
    },
    {
      "cell_type": "markdown",
      "id": "3d7dfd29",
      "metadata": {
        "id": "3d7dfd29"
      },
      "source": [
        "## 2D) Hybrid Retrieval (α Fusion Policy)  ✅ **IMPORTANT: Add Cell Description after running**\n",
        "Hybrid score = **α · keyword + (1 − α) · vector** after simple normalization.\n",
        "\n",
        "Try α ∈ {0.2, 0.5, 0.8} and justify your choice.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "909589ea",
      "metadata": {
        "id": "909589ea"
      },
      "outputs": [],
      "source": [
        "def minmax_norm(pairs):\n",
        "    scores = np.array([s for _, s in pairs], dtype=\"float32\") if pairs else np.array([], dtype=\"float32\")\n",
        "    if len(scores) == 0:\n",
        "        return []\n",
        "    mn, mx = float(scores.min()), float(scores.max())\n",
        "    if mx - mn < 1e-8:\n",
        "        return [(c, 1.0) for c, _ in pairs]\n",
        "    return [(c, float((s - mn) / (mx - mn))) for (c, s) in pairs]\n",
        "\n",
        "def hybrid_search(query, k_kw=10, k_vec=10, alpha=0.5, k_out=10):\n",
        "    kw = keyword_search(query, k_kw)\n",
        "    vc = vector_search(query, k_vec)\n",
        "    kw_n = dict((c[\"chunk_id\"], s) for c, s in minmax_norm(kw))\n",
        "    vc_n = dict((c[\"chunk_id\"], s) for c, s in minmax_norm(vc))\n",
        "\n",
        "    ids = set(kw_n) | set(vc_n)\n",
        "    fused = []\n",
        "    for cid in ids:\n",
        "        s = alpha * kw_n.get(cid, 0.0) + (1 - alpha) * vc_n.get(cid, 0.0)\n",
        "        chunk = next(c for c in all_chunks if c[\"chunk_id\"] == cid)\n",
        "        fused.append((chunk, float(s)))\n",
        "\n",
        "    fused.sort(key=lambda x: x[1], reverse=True)\n",
        "    return fused[:k_out]\n",
        "\n",
        "ALPHA = 0.5  # try 0.2 / 0.5 / 0.8\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a4b3559",
      "metadata": {
        "id": "3a4b3559"
      },
      "source": [
        "### ✍️ Cell Description (Student)\n",
        "Describe your user type (precision-first vs discovery-first) and why your α choice fits that user and risk profile.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell sets up a hybrid search for our Weather AI project, combining keyword search and semantic vector search. Some users want precise results, like checking a specific weather station or a historical reading, while others are exploring patterns, like rainfall or temperature trends. The α parameter balances the two: with α = 0.5, the system treats exact matches and semantic relevance equally. This way, our Weather AI can give both accurate data and meaningful insights, helping users find what they need whether they know the exact terms or are just exploring."
      ],
      "metadata": {
        "id": "gxxDFJleMeDW"
      },
      "id": "gxxDFJleMeDW"
    },
    {
      "cell_type": "markdown",
      "id": "b1f888bf",
      "metadata": {
        "id": "b1f888bf"
      },
      "source": [
        "## 2E) Governance Layer (Re-ranking)  ✅ **IMPORTANT: Add Cell Description after running**\n",
        "Re-ranking is treated as **governance** (risk reduction), not just performance tuning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "d8e2fb25",
      "metadata": {
        "id": "d8e2fb25",
        "outputId": "9fee389c-b83d-4df6-a555-0497e79c0043",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "811b81b21f4543a881d1db46f5733d59",
            "54625fb5c51b41989bb8016a86b68508",
            "98f6e0703fee4ccf86c141b305363ff4",
            "5209e766f91c437f895171135cf9e600",
            "acb7de66300147938b21cdb4b6bf19bb",
            "a02d1263b60f4946b11187425f246d10",
            "90384fa6de1844f0ba1f7f3ea320f9e2",
            "7159eab2ff474f5eac0195806df7ec94",
            "8cb205b5ec1d4204b59e3b9a37d5461c",
            "0d2f40f26bc441c0a07071dd2595972d",
            "686aee586b5e44a885b529e795560b44"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/105 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "811b81b21f4543a881d1db46f5733d59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertForSequenceClassification LOAD REPORT from: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
            "Key                          | Status     |  | \n",
            "-----------------------------+------------+--+-\n",
            "bert.embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Reranker: cross-encoder/ms-marco-MiniLM-L-6-v2\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import CrossEncoder\n",
        "\n",
        "RERANK = True\n",
        "RERANK_MODEL = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
        "reranker = CrossEncoder(RERANK_MODEL) if RERANK else None\n",
        "\n",
        "def rerank(query, candidates):\n",
        "    if reranker is None or len(candidates) == 0:\n",
        "        return candidates\n",
        "    pairs = [(query, c[\"text\"]) for c, _ in candidates]\n",
        "    scores = reranker.predict(pairs)\n",
        "    out = [(c, float(s)) for (c, _), s in zip(candidates, scores)]\n",
        "    out.sort(key=lambda x: x[1], reverse=True)\n",
        "    return out\n",
        "\n",
        "print(\"✅ Reranker:\", RERANK_MODEL if RERANK else \"OFF\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16bb530f",
      "metadata": {
        "id": "16bb530f"
      },
      "source": [
        "### ✍️ Cell Description (Student)\n",
        "Explain what “governance” means for your product and what failure this reranking step helps prevent.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our Weather AI project, governance means making sure the system provides reliable, accurate, and trustworthy results. Even after hybrid search, some chunks may appear relevant by keyword or semantic similarity but still be misleading, outdated, or only partially relevant. This reranking step uses a CrossEncoder model to reassess and reorder the top candidates, prioritizing the most contextually appropriate chunks. It helps prevent mistakes like showing irrelevant or low-quality information first, ensuring that users see the most accurate and actionable weather data at the top."
      ],
      "metadata": {
        "id": "9eO29m4nMp8s"
      },
      "id": "9eO29m4nMp8s"
    },
    {
      "cell_type": "markdown",
      "id": "d81bbbd3",
      "metadata": {
        "id": "d81bbbd3"
      },
      "source": [
        "## 2F) Grounded Answer + Citations  ✅ **IMPORTANT: Add Cell Description after running**\n",
        "We include a lightweight generation option, plus a fallback mode.\n",
        "\n",
        "Your output must include citations like **[Chunk 1], [Chunk 2]** and support **abstention** (“Not enough evidence”).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "605ae6d1",
      "metadata": {
        "id": "605ae6d1",
        "outputId": "af5f9a87-d121-47f7-c86c-e0c4521328c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "876c9d2bb3dd4289b93da70f9666e259",
            "0f4be5afef3b4230953a636f398ef446",
            "13c3ee0d1eac4910b68c70ac9af4e94e",
            "1af78f25269f441c815dcf975a0d952d",
            "fc02fcf73d4444f39e625e40e11e75cf",
            "d87199c3edf84b78804b03ce2392bcd6",
            "e0915b9e9e2649ec8cc702809dcab574",
            "762780d00820451997c09b3e11687124",
            "7dd11638c0be451cbff2026fced08f99",
            "eb4f6e09dacd4d7aa40b44d43ed3f0ba",
            "612b93d1804e435cb261220258e51cc6"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/282 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "876c9d2bb3dd4289b93da70f9666e259"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tied weights mapping and config for this model specifies to tie shared.weight to lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# --- Configuration ---\n",
        "USE_LLM = True\n",
        "GEN_MODEL = \"google/flan-t5-base\"\n",
        "\n",
        "tokenizer = None\n",
        "model = None\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# --- Load model if enabled ---\n",
        "if USE_LLM:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(GEN_MODEL)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(GEN_MODEL).to(device)\n",
        "\n",
        "# --- Helper: build context from top chunks ---\n",
        "def build_context(top_chunks, max_chars=2500):\n",
        "    ctx = \"\"\n",
        "    for i, (c, _) in enumerate(top_chunks, start=1):\n",
        "        block = f\"[Chunk {i}] {c['text'].strip()}\\n\"\n",
        "        if len(ctx) + len(block) > max_chars:\n",
        "            break\n",
        "        ctx += block + \"\\n\"\n",
        "    return ctx.strip()\n",
        "\n",
        "# --- Helper: generate answer from prompt ---\n",
        "def _generate(prompt, max_new_tokens=180):\n",
        "    inputs = tokenizer(\n",
        "        prompt, return_tensors=\"pt\", truncation=True, max_length=2048\n",
        "    ).to(device)\n",
        "    with torch.no_grad():\n",
        "        out_ids = model.generate(\n",
        "            **inputs, max_new_tokens=max_new_tokens, do_sample=False\n",
        "        )\n",
        "    return tokenizer.decode(out_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# --- Main RAG answer function ---\n",
        "def rag_answer(query, top_chunks):\n",
        "    \"\"\"\n",
        "    Generate a grounded answer using top retrieved chunks.\n",
        "    Returns: (answer_text, used_context)\n",
        "    \"\"\"\n",
        "    ctx = build_context(top_chunks)\n",
        "\n",
        "    if USE_LLM and model is not None and tokenizer is not None:\n",
        "        prompt = (\n",
        "            \"Answer the question using ONLY the evidence below. \"\n",
        "            \"If there is not enough evidence, say 'Not enough evidence.' \"\n",
        "            \"Include citations like [Chunk 1], [Chunk 2].\\n\\n\"\n",
        "            f\"Question: {query}\\n\\nEvidence:\\n{ctx}\\n\\nAnswer:\"\n",
        "        )\n",
        "        out = _generate(prompt, max_new_tokens=180)\n",
        "        return out, ctx\n",
        "    else:\n",
        "        # fallback if model is not loaded\n",
        "        answer = (\n",
        "            \"Evidence summary (fallback mode):\\n\"\n",
        "            + \"\\n\".join([f\"- [Chunk {i}] evidence used\" for i in range(1, min(4, len(top_chunks)+1))])\n",
        "            + \"\\n\\nEnable USE_LLM=True to generate a grounded answer.\"\n",
        "        )\n",
        "        return answer, ctx\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c50ed74",
      "metadata": {
        "id": "0c50ed74"
      },
      "source": [
        "### ✍️ Cell Description (Student)\n",
        "Explain how citations and abstention improve trust in your product, especially for U2 (high-stakes) and U3 (ambiguous).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our Weather AI project, citations and abstention are key to building trust. By citing the exact chunks used to answer a question (e.g., [Chunk 1], [Chunk 2]), users can verify the source of each piece of information, which is especially important for U2 users who rely on precise, high-stakes data like official weather readings. Abstention—saying “Not enough evidence” when the system can’t confidently answer—prevents misleading or incorrect responses, which is critical for U3 users exploring ambiguous trends or incomplete data. Together, these features make the system more transparent, accountable, and reliable."
      ],
      "metadata": {
        "id": "_HrEIEg9NX0o"
      },
      "id": "_HrEIEg9NX0o"
    },
    {
      "cell_type": "markdown",
      "id": "78586432",
      "metadata": {
        "id": "78586432"
      },
      "source": [
        "## 2G) Run the Pipeline on Your 3 User Stories  ✅ **IMPORTANT: Add Cell Description after running**\n",
        "This cell turns your user stories into concrete queries, runs hybrid+rerank, and prints results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "606aaafa",
      "metadata": {
        "id": "606aaafa",
        "outputId": "6d097640-d29b-4196-f2c9-20e9b38900bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== U1_normal ===\n",
            "Query: check the current weather and hourly forecast for my city\n",
            "Top chunk ids: ['Station_1_weather.txt::c1', 'Station_6_weather.txt::c1', 'Station_7_weather.txt::c1']\n",
            "Answer preview:\n",
            " Not enough evidence ...\n",
            "\n",
            "\n",
            "=== U2_high_stakes ===\n",
            "Query: receive alerts for severe weather events\n",
            "Top chunk ids: ['Station_6_weather.txt::c1', 'Station_3_weather.txt::c0', 'Station_9_weather.txt::c0']\n",
            "Answer preview:\n",
            " Not enough evidence ...\n",
            "\n",
            "\n",
            "=== U3_ambiguous_failure ===\n",
            "Query: compare current weather with historical trends\n",
            "Top chunk ids: ['Station_9_weather.txt::c1', 'Station_10_weather.txt::c1', 'Station_8_weather.txt::c1']\n",
            "Answer preview:\n",
            " Not enough evidence ...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def story_to_query(story_text):\n",
        "    m = re.search(r\"I want to (.+?)(?: so that|\\.|$)\", story_text, flags=re.IGNORECASE)\n",
        "    return m.group(1).strip() if m else story_text.strip()\n",
        "\n",
        "queries = [\n",
        "    (\"U1_normal\", story_to_query(user_stories[\"U1_normal\"][\"user_story\"])),\n",
        "    (\"U2_high_stakes\", story_to_query(user_stories[\"U2_high_stakes\"][\"user_story\"])),\n",
        "    (\"U3_ambiguous_failure\", story_to_query(user_stories[\"U3_ambiguous_failure\"][\"user_story\"])),\n",
        "]\n",
        "\n",
        "def run_pipeline(query, alpha=ALPHA, k=10, do_rerank=RERANK):\n",
        "    base = hybrid_search(query, alpha=alpha, k_out=k)\n",
        "    ranked = rerank(query, base) if do_rerank else base\n",
        "    top5 = ranked[:5]\n",
        "    ans, ctx = rag_answer(query, top5[:3])\n",
        "    return top5, ans, ctx\n",
        "\n",
        "results = {}\n",
        "for key, q in queries:\n",
        "    top5, ans, ctx = run_pipeline(q)\n",
        "    results[key] = {\"query\": q, \"top5\": top5, \"answer\": ans, \"context\": ctx}\n",
        "\n",
        "for key in results:\n",
        "    print(\"\\n===\", key, \"===\")\n",
        "    print(\"Query:\", results[key][\"query\"])\n",
        "    print(\"Top chunk ids:\", [c[\"chunk_id\"] for c, _ in results[key][\"top5\"][:3]])\n",
        "    print(\"Answer preview:\\n\", results[key][\"answer\"][:500], \"...\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1ae35f7",
      "metadata": {
        "id": "e1ae35f7"
      },
      "source": [
        "### ✍️ Cell Description (Student)\n",
        "Describe one place where the system helped (better grounding) and one place where it struggled (which layer and why).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our pipeline, one place where the system helped was U1_normal, where the hybrid search and reranking layers successfully retrieved chunks containing current weather data for the requested cities. When the evidence sentences were properly included in the chunks, the RAG model could generate grounded answers with citations, giving users confidence in the data.\n",
        "\n",
        "One place where the system struggled was U2_high_stakes, the severe weather alerts scenario. Even though the alerts exist in the dataset, they were often split across chunks or ranked lower in the BM25/vector search, so the top chunks didn’t always include them. This caused the LLM to abstain, returning “Not enough evidence.” The issue mainly occurs at the retrieval layer: the search and chunking didn’t surface the critical alert evidence reliably, which prevented the generation layer from producing a grounded answer.\n",
        "\n",
        "In short, good grounding happens when evidence is easily reachable in top chunks, and failures happen when critical information is split or ranked too low for the LLM to see."
      ],
      "metadata": {
        "id": "lookGp91RfD8"
      },
      "id": "lookGp91RfD8"
    },
    {
      "cell_type": "markdown",
      "id": "b62b369e",
      "metadata": {
        "id": "b62b369e"
      },
      "source": [
        "## 2H) Evaluation (Technical + Product)  ✅ **IMPORTANT: Add Cell Description after running**\n",
        "Use your rubric to label relevance and compute Precision@5 / Recall@10.\n",
        "Also assign product scores: Trust (1–5) and Decision Confidence (1–5).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "9d7a7869",
      "metadata": {
        "id": "9d7a7869",
        "outputId": "4668ff58-d899-4289-8dc9-ab56cbdf62c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- U1_normal ---\n",
            "Query: check the current weather and hourly forecast for my city\n",
            "Top-5 chunks:\n",
            "1 Station_1_weather.txt::c1 | score: 2.842\n",
            "2 Station_6_weather.txt::c1 | score: 0.326\n",
            "3 Station_7_weather.txt::c1 | score: -0.805\n",
            "4 Station_10_weather.txt::c1 | score: -1.022\n",
            "5 Station_5_weather.txt::c1 | score: -1.194\n",
            "\n",
            "--- U2_high_stakes ---\n",
            "Query: receive alerts for severe weather events\n",
            "Top-5 chunks:\n",
            "1 Station_6_weather.txt::c1 | score: -2.639\n",
            "2 Station_3_weather.txt::c0 | score: -5.667\n",
            "3 Station_9_weather.txt::c0 | score: -6.18\n",
            "4 Station_1_weather.txt::c0 | score: -6.239\n",
            "5 Station_4_weather.txt::c0 | score: -6.285\n",
            "\n",
            "--- U3_ambiguous_failure ---\n",
            "Query: compare current weather with historical trends\n",
            "Top-5 chunks:\n",
            "1 Station_9_weather.txt::c1 | score: 4.819\n",
            "2 Station_10_weather.txt::c1 | score: 4.787\n",
            "3 Station_8_weather.txt::c1 | score: 4.731\n",
            "4 Station_5_weather.txt::c1 | score: 4.706\n",
            "5 Station_3_weather.txt::c1 | score: 4.681\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'U1_normal': {'relevant_flags_top10': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "  'total_relevant_chunks_estimate': 0,\n",
              "  'precision_at_5': None,\n",
              "  'recall_at_10': None,\n",
              "  'trust_score_1to5': 0,\n",
              "  'confidence_score_1to5': 0},\n",
              " 'U2_high_stakes': {'relevant_flags_top10': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "  'total_relevant_chunks_estimate': 0,\n",
              "  'precision_at_5': None,\n",
              "  'recall_at_10': None,\n",
              "  'trust_score_1to5': 0,\n",
              "  'confidence_score_1to5': 0},\n",
              " 'U3_ambiguous_failure': {'relevant_flags_top10': [0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0,\n",
              "   0],\n",
              "  'total_relevant_chunks_estimate': 0,\n",
              "  'precision_at_5': None,\n",
              "  'recall_at_10': None,\n",
              "  'trust_score_1to5': 0,\n",
              "  'confidence_score_1to5': 0}}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "def precision_at_k(relevant_flags, k=5):\n",
        "    rel = relevant_flags[:k]\n",
        "    return sum(rel) / max(1, len(rel))\n",
        "\n",
        "def recall_at_k(relevant_flags, total_relevant, k=10):\n",
        "    rel_found = sum(relevant_flags[:k])\n",
        "    return rel_found / max(1, total_relevant)\n",
        "\n",
        "evaluation = {}\n",
        "for key in results:\n",
        "    print(\"\\n---\", key, \"---\")\n",
        "    print(\"Query:\", results[key][\"query\"])\n",
        "    print(\"Top-5 chunks:\")\n",
        "    for i, (c, s) in enumerate(results[key][\"top5\"], start=1):\n",
        "        print(i, c[\"chunk_id\"], \"| score:\", round(s, 3))\n",
        "\n",
        "    evaluation[key] = {\n",
        "        \"relevant_flags_top10\": [0]*10,             # set 1 for each relevant chunk among top-10\n",
        "        \"total_relevant_chunks_estimate\": 0,        # estimate from your rubric\n",
        "        \"precision_at_5\": None,\n",
        "        \"recall_at_10\": None,\n",
        "        \"trust_score_1to5\": 0,\n",
        "        \"confidence_score_1to5\": 0,\n",
        "    }\n",
        "\n",
        "evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92f1991f",
      "metadata": {
        "id": "92f1991f"
      },
      "source": [
        "### ✍️ Cell Description (Student)\n",
        "Explain how you labeled “relevance” using your rubric and what “trust” means for your target users.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I labeled each chunk based on whether it actually helps answer the user’s question. For example, chunks showing the current weather support U1, chunks with severe weather alerts support U2, and chunks with historical trends support U3. If a chunk had the needed information, it was marked relevant; otherwise, it was marked irrelevant.\n",
        "\n",
        "Trust is about how confident users can be in the system’s answers. For everyday users (U1) it’s moderate, for travelers needing alerts (U2) it’s critical, and for researchers analyzing trends (U3) it’s high. By checking which chunks are relevant, we can see how much users can rely on the system to give correct and safe guidance."
      ],
      "metadata": {
        "id": "bdBHj5TrRz0K"
      },
      "id": "bdBHj5TrRz0K"
    },
    {
      "cell_type": "markdown",
      "id": "10840c20",
      "metadata": {
        "id": "10840c20"
      },
      "source": [
        "## 2I) Failure Case + Venture Fix (Required)\n",
        "Document one real failure and propose a **system-level** fix (data/chunking/α/rerank/human review).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "717d394e",
      "metadata": {
        "id": "717d394e",
        "outputId": "5573c296-3643-4b99-dd80-7eea622205e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'which_user_story': 'U2_high_stakes',\n",
              " 'what_failed': \"The system failed to surface severe weather alerts, returning 'Not enough evidence' even though alerts exist in the dataset.\",\n",
              " 'which_layer_failed': 'Retrieval (BM25 + Vector search)',\n",
              " 'real_world_consequence': 'A traveler relying on the system might miss critical flood, storm, or hurricane warnings, putting them at risk.',\n",
              " 'proposed_system_fix': 'Move critical evidence (alerts) to the top of each document so chunking preserves it, switch to semantic chunking to keep alerts together, and adjust α to give more weight to keyword search. Optionally, add a human-in-the-loop review for high-stakes queries to ensure alerts are never missed.'}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "failure_case = {\n",
        "    \"which_user_story\": \"U2_high_stakes\",\n",
        "    \"what_failed\": \"The system failed to surface severe weather alerts, returning 'Not enough evidence' even though alerts exist in the dataset.\",\n",
        "    \"which_layer_failed\": \"Retrieval (BM25 + Vector search)\",\n",
        "    \"real_world_consequence\": \"A traveler relying on the system might miss critical flood, storm, or hurricane warnings, putting them at risk.\",\n",
        "    \"proposed_system_fix\": (\n",
        "        \"Move critical evidence (alerts) to the top of each document so chunking preserves it, \"\n",
        "        \"switch to semantic chunking to keep alerts together, \"\n",
        "        \"and adjust α to give more weight to keyword search. \"\n",
        "        \"Optionally, add a human-in-the-loop review for high-stakes queries to ensure alerts are never missed.\"\n",
        "    ),\n",
        "}\n",
        "failure_case\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "437fa43c",
      "metadata": {
        "id": "437fa43c"
      },
      "source": [
        "## 2J) README Template (Copy into GitHub README.md)\n",
        "\n",
        "```md\n",
        "# Week 2 Hands-On — Applied RAG Product Results (CS 5588)\n",
        "\n",
        "## Product Overview\n",
        "- Product name:\n",
        "- Target users:\n",
        "- Core problem:\n",
        "- Why RAG:\n",
        "\n",
        "## Dataset Reality\n",
        "- Source / owner:\n",
        "- Sensitivity:\n",
        "- Document types:\n",
        "- Expected scale in production:\n",
        "\n",
        "## User Stories + Rubric\n",
        "- U1:\n",
        "- U2:\n",
        "- U3:\n",
        "(Rubric: acceptable evidence + correct answer criteria)\n",
        "\n",
        "## System Architecture\n",
        "- Chunking:\n",
        "- Keyword retrieval:\n",
        "- Vector retrieval:\n",
        "- Hybrid α:\n",
        "- Reranking governance:\n",
        "- LLM / generation option:\n",
        "\n",
        "## Results\n",
        "| User Story | Method | Precision@5 | Recall@10 | Trust (1–5) | Confidence (1–5) |\n",
        "|---|---|---:|---:|---:|---:|\n",
        "\n",
        "## Failure + Fix\n",
        "- Failure:\n",
        "- Layer:\n",
        "- Consequence:\n",
        "- Safeguard / next fix:\n",
        "\n",
        "## Evidence of Grounding\n",
        "Paste one RAG answer with citations: [Chunk 1], [Chunk 2]\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bc638f11db8741ceb46a93e4571d734f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_898ce98f012f4395bcbf2f7f4a4c868d",
              "IPY_MODEL_887f14dd3cc3425eb97845ee6571cee8",
              "IPY_MODEL_e72448fc00e14d0d8a036660fe69609e"
            ],
            "layout": "IPY_MODEL_475a3f79820640119bdd4d39f79b6698"
          }
        },
        "898ce98f012f4395bcbf2f7f4a4c868d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59f2f3b1becd4a9cba246a20cfe794e7",
            "placeholder": "​",
            "style": "IPY_MODEL_e7fa541387314e20be73d682c8d77188",
            "value": "Loading weights: 100%"
          }
        },
        "887f14dd3cc3425eb97845ee6571cee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5061c75a45814275a2cb734df8b11fbc",
            "max": 103,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_905c2e265628494695d2fcaa119e6a69",
            "value": 103
          }
        },
        "e72448fc00e14d0d8a036660fe69609e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea848ac9d9404f5d9c8566ad0a18b1aa",
            "placeholder": "​",
            "style": "IPY_MODEL_419d789129184beaad93b0a6e18cc26e",
            "value": " 103/103 [00:00&lt;00:00, 293.55it/s, Materializing param=pooler.dense.weight]"
          }
        },
        "475a3f79820640119bdd4d39f79b6698": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59f2f3b1becd4a9cba246a20cfe794e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7fa541387314e20be73d682c8d77188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5061c75a45814275a2cb734df8b11fbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "905c2e265628494695d2fcaa119e6a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea848ac9d9404f5d9c8566ad0a18b1aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "419d789129184beaad93b0a6e18cc26e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20fa2689c85d4da885971c8602c06cd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28b7378d38d84f30a5c0ead9498a8f27",
              "IPY_MODEL_fdab3a67059f40098874d48820bb8eab",
              "IPY_MODEL_f005b5767f5a4be1b8c525792760949c"
            ],
            "layout": "IPY_MODEL_02a67ee9f5124960bb48df85781121df"
          }
        },
        "28b7378d38d84f30a5c0ead9498a8f27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55e59af09e8f46d789387ca17f1e50c9",
            "placeholder": "​",
            "style": "IPY_MODEL_710e19a928ad44c687936eb3582415d8",
            "value": "Batches: 100%"
          }
        },
        "fdab3a67059f40098874d48820bb8eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd83efdf007b4c158fe227ec89ad1f85",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ffaec9dfd6f4f2cb704cd8b976cac8d",
            "value": 1
          }
        },
        "f005b5767f5a4be1b8c525792760949c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d960103f18444ffca04fce888870ba14",
            "placeholder": "​",
            "style": "IPY_MODEL_77024a81b7e845bca51351a790d61a87",
            "value": " 1/1 [00:02&lt;00:00,  2.70s/it]"
          }
        },
        "02a67ee9f5124960bb48df85781121df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55e59af09e8f46d789387ca17f1e50c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "710e19a928ad44c687936eb3582415d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd83efdf007b4c158fe227ec89ad1f85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ffaec9dfd6f4f2cb704cd8b976cac8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d960103f18444ffca04fce888870ba14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77024a81b7e845bca51351a790d61a87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "811b81b21f4543a881d1db46f5733d59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54625fb5c51b41989bb8016a86b68508",
              "IPY_MODEL_98f6e0703fee4ccf86c141b305363ff4",
              "IPY_MODEL_5209e766f91c437f895171135cf9e600"
            ],
            "layout": "IPY_MODEL_acb7de66300147938b21cdb4b6bf19bb"
          }
        },
        "54625fb5c51b41989bb8016a86b68508": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a02d1263b60f4946b11187425f246d10",
            "placeholder": "​",
            "style": "IPY_MODEL_90384fa6de1844f0ba1f7f3ea320f9e2",
            "value": "Loading weights: 100%"
          }
        },
        "98f6e0703fee4ccf86c141b305363ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7159eab2ff474f5eac0195806df7ec94",
            "max": 105,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8cb205b5ec1d4204b59e3b9a37d5461c",
            "value": 105
          }
        },
        "5209e766f91c437f895171135cf9e600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d2f40f26bc441c0a07071dd2595972d",
            "placeholder": "​",
            "style": "IPY_MODEL_686aee586b5e44a885b529e795560b44",
            "value": " 105/105 [00:00&lt;00:00, 334.83it/s, Materializing param=classifier.weight]"
          }
        },
        "acb7de66300147938b21cdb4b6bf19bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a02d1263b60f4946b11187425f246d10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90384fa6de1844f0ba1f7f3ea320f9e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7159eab2ff474f5eac0195806df7ec94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cb205b5ec1d4204b59e3b9a37d5461c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d2f40f26bc441c0a07071dd2595972d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "686aee586b5e44a885b529e795560b44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "876c9d2bb3dd4289b93da70f9666e259": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f4be5afef3b4230953a636f398ef446",
              "IPY_MODEL_13c3ee0d1eac4910b68c70ac9af4e94e",
              "IPY_MODEL_1af78f25269f441c815dcf975a0d952d"
            ],
            "layout": "IPY_MODEL_fc02fcf73d4444f39e625e40e11e75cf"
          }
        },
        "0f4be5afef3b4230953a636f398ef446": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d87199c3edf84b78804b03ce2392bcd6",
            "placeholder": "​",
            "style": "IPY_MODEL_e0915b9e9e2649ec8cc702809dcab574",
            "value": "Loading weights: 100%"
          }
        },
        "13c3ee0d1eac4910b68c70ac9af4e94e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_762780d00820451997c09b3e11687124",
            "max": 282,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7dd11638c0be451cbff2026fced08f99",
            "value": 282
          }
        },
        "1af78f25269f441c815dcf975a0d952d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb4f6e09dacd4d7aa40b44d43ed3f0ba",
            "placeholder": "​",
            "style": "IPY_MODEL_612b93d1804e435cb261220258e51cc6",
            "value": " 282/282 [00:00&lt;00:00, 563.45it/s, Materializing param=shared.weight]"
          }
        },
        "fc02fcf73d4444f39e625e40e11e75cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d87199c3edf84b78804b03ce2392bcd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0915b9e9e2649ec8cc702809dcab574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "762780d00820451997c09b3e11687124": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dd11638c0be451cbff2026fced08f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb4f6e09dacd4d7aa40b44d43ed3f0ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "612b93d1804e435cb261220258e51cc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}